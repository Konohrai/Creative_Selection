{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a072d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import pickle\n",
    "import pymc3 as pm\n",
    "\n",
    "# SetUp the path\n",
    "path = os.chdir('/Users/mac/Documents/Voodoo/ADN-DS')\n",
    "\n",
    "# Load_data\n",
    "df_all = pd.read_csv('modeling_ipm_data_v2.csv', index_col = False)\n",
    "\n",
    "# Get last 7 days from dataset (embedding includet into last date)\n",
    "df_all = df_all[pd.to_datetime(df_all['date']) == pd.to_datetime(df_all.date.max())]\n",
    "\n",
    "# Group data and calculate 'total_impressions' and 'total_install'\n",
    "def Total_Data_IPM(df, features, group_by_feature, sort_features):    \n",
    "\n",
    "        # Create dataset for AD Selection task\n",
    "        df = df[features]\n",
    "\n",
    "        df_grouped = df.groupby(group_by_feature)['window_impressions', 'window_installs'].sum()\n",
    "\n",
    "        df_grouped.rename(columns = {'window_impressions':'total_impressions', 'window_installs':'total_install'}, inplace = True)\n",
    "\n",
    "        df = df_grouped.reset_index()\n",
    "\n",
    "        # Sort values\n",
    "        df.sort_values(sort_features)\n",
    "\n",
    "        return df\n",
    "    \n",
    "def train_model(df_all):\n",
    "   \n",
    "    # Grouping data for model\n",
    "    df_group = Total_Data_IPM(df_all, \n",
    "                             ['promoted_app', 'ad_id', 'window_impressions','window_installs'], \n",
    "                             ['promoted_app', \"ad_id\"],\n",
    "                              'promoted_app')\n",
    "    \n",
    "    # Set variables\n",
    "    n = df_group['total_impressions'].values\n",
    "    k = df_group['total_install'].values\n",
    "\n",
    "    # Build model for each day\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # Set priors\n",
    "        alpha = pm.Uniform('alpha', 1e-3, 1e5)\n",
    "        beta = pm.Uniform('beta',  1e-3, 1e5)\n",
    "\n",
    "        p = pm.Beta('p', alpha = alpha, beta = beta, shape = len(n))\n",
    "\n",
    "        # Specify model\n",
    "        obs = pm.Binomial('obs', n = n, p = p, observed = k) # (C_n)^k * p^k * (1-p)^(n-k) \n",
    "\n",
    "        # Configure sampler.\n",
    "        trace = pm.sample(\n",
    "                        #draws = int(1e4), # The number of samples to draw (1e4)\n",
    "                        #tune = int(5e3), # Number of iterations to tune (5e3)\n",
    "                        target_accept = 0.9, #  The step size is tuned such that we approximate this acceptance rate. Higher values like 0.9 or 0.95 often work better for problematic posteriors. \n",
    "                        return_inferencedata = True, # return the trace as an arviz.InferenceData (True) object\n",
    "                        idata_kwargs = {'log_likelihood': False},\n",
    "                        random_seed = 42) \n",
    "    \n",
    "    # Save model\n",
    "    with open('Model/ad_selection_model.pkl', 'wb') as buff:\n",
    "        pickle.dump({'model': model, 'trace': trace}, buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0632e27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/57/nx0ld9vx17l0yw9shbwxhk440000gn/T/ipykernel_1174/3783839664.py:24: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_grouped = df.groupby(group_by_feature)['window_impressions', 'window_installs'].sum()\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [p, beta, alpha]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 02:57<00:00 Sampling 4 chains, 2,067 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 193 seconds.\n",
      "There were 805 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.5560800464733382, but should be close to 0.9. Try to increase the number of tuning steps.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "There were 837 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7288551068352215, but should be close to 0.9. Try to increase the number of tuning steps.\n",
      "There were 424 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7569392917870286, but should be close to 0.9. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "train_model(df_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
